{
  "models": [
    {
      "name": "distilgpt2",
      "description": "Ultra-light, fastest model for testing",
      "requires_auth": false,
      "torch_dtype": "float16"
    },
    {
      "name": "gpt2",
      "description": "Slightly bigger, very stable model",
      "requires_auth": false,
      "torch_dtype": "float16"
    },
    {
      "name": "gpt2-medium",
      "description": "Mid-sized GPT-2 model (~355M params), better quality than base gpt2",
      "requires_auth": false,
      "torch_dtype": "float16"
    },
    {
      "name": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
      "description": "Small chat-style model",
      "requires_auth": false,
      "torch_dtype": "float16"
    },
    {
      "name": "meta-llama/Llama-3.1-8B-Instruct",
      "description": "Llama 3.1 8B Instruct via dedicated Inference Endpoint",
      "requires_auth": true,
      "remote_type": "hf_inference_endpoint",
      "endpoint_url": "https://wacdy6ihswnfwbk1.us-east-1.aws.endpoints.huggingface.cloud",
      "endpoint_namespace": "tsakirogf",
      "endpoint_name": "llama-3-1-8b-instruct-hgr"
    }
  ]
}
